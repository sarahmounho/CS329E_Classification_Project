{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import intake_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsample, StandardScaler, SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Scale Data\n",
    "\n",
    "Removed 3 features: days, ventilator weaning, ventilator free days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pre = intake_data()\n",
    "data_x = data_pre.drop([\"death\",\"days.1\",\"ventilator weaning = 1\", \"VFD \",\"days\"], axis=1)\n",
    "data_y = data_pre[\"death\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import over_sampling\n",
    "oversample = over_sampling.SMOTE()\n",
    "smote_x, smote_y = oversample.fit_resample(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaled_x = smote_x\n",
    "scaled_y = smote_y \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(scaled_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best parameters\n",
    "\n",
    "Finding best number of n neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "param_list = []\n",
    "for i in range(1,31): \n",
    "    param_list.append(i)\n",
    "parameters = {'n_neighbors':param_list}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), parameters, cv = 10)\n",
    "gs_results = gs.fit(smote_x, smote_y)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running cross validation loop with n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.77      0.66       128\n",
      "         1.0       0.66      0.45      0.53       128\n",
      "\n",
      "    accuracy                           0.61       256\n",
      "   macro avg       0.62      0.61      0.60       256\n",
      "weighted avg       0.62      0.61      0.60       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "my_model = KNeighborsClassifier(n_neighbors = 2)\n",
    "my_model.fit(scaled_x, scaled_y)\n",
    "cross_val_score(my_model, scaled_x, scaled_y, cv = 10)\n",
    "y_predict = cross_val_predict(my_model, scaled_x, scaled_y, cv=10)\n",
    "print(classification_report(scaled_y, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.55      0.61       128\n",
      "         1.0       0.63      0.77      0.69       128\n",
      "\n",
      "    accuracy                           0.66       256\n",
      "   macro avg       0.66      0.66      0.65       256\n",
      "weighted avg       0.66      0.66      0.65       256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_val_score(gs, scaled_x, scaled_y, cv=10)\n",
    "y_predict = cross_val_predict(gs, scaled_x, scaled_y, cv=10)\n",
    "print(classification_report(scaled_y, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing PCA dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.3s finished\n",
      "\n",
      "[2020-04-17 13:59:42] Features: 1/5 -- score: 0.6023378582202111[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.3s finished\n",
      "\n",
      "[2020-04-17 13:59:42] Features: 2/5 -- score: 0.6137254901960785[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    0.3s finished\n",
      "\n",
      "[2020-04-17 13:59:42] Features: 3/5 -- score: 0.6097285067873304[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.2s finished\n",
      "\n",
      "[2020-04-17 13:59:43] Features: 4/5 -- score: 0.5937405731523377[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.2s finished\n",
      "\n",
      "[2020-04-17 13:59:43] Features: 5/5 -- score: 0.5976621417797887"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7538461538461538\n",
      "{'knn__n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define a pipeline to search for the best combination of \n",
    "# PCA dimensions and n_neighbors.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#crate a scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#create a PCA\n",
    "sfs = sfs(knn, k_features=5, forward=True, floating=False,\n",
    "          verbose=2, scoring='accuracy', cv=5)\n",
    "sfs.fit(smote_x, smote_y)\n",
    "\n",
    "#create a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#create a pipeline that does scaling, then PCA, then KNN\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('knn', knn)])\n",
    "\n",
    "#Set up the parameters you want to tune for each of your pipeline steps\n",
    "#Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(1, 30)),  #find the best value of k\n",
    "}\n",
    "\n",
    "# pass the pipeline and the parameters into a GridSearchCV with a 5-fold cross validation\n",
    "gs = GridSearchCV(pipe, param_grid, cv=5)\n",
    "# call fit() on the GridSearchCV and pass in the unscaled data (X_values, Y_values)\n",
    "x = smote_x\n",
    "y = smote_y\n",
    "gs.fit(x,y)\n",
    "# print out the best_score_ and best_params_ from the GridSearchCV\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding final accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68359375"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "cross_val_score(gs, x, y, cv=5)\n",
    "y_predict = cross_val_predict(gs, x, y, cv=5)\n",
    "accuracy_score(y, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
